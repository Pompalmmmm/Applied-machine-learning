# Resources

## Cornell lab

https://github.com/ekaratnida/cornell-cs5785-2020-applied-ml/blob/main/notebooks/lecture12-decision-trees.ipynb

## Gini VS Entropy

https://quantdare.com/decision-trees-gini-vs-entropy/

https://explained.ai/decision-tree-viz/

https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/ml-decision-tree/tutorial/

https://www.learnbymarketing.com/481/decision-tree-flavors-gini-info-gain/

What is the gini index of the root node generated by SKLearn https://www.learndatasci.com/glossary/gini-impurity/

## Trees, Forests, Bagging, and Boosting [p.599 ~ 619]
https://github.com/probml/pml-book/releases/latest/download/book1.pdf

## Information
scikit-learn uses an optimised version of the CART algorithm. </br>
https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier

## SHAP
https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf

## Regression
https://saedsayad.com/decision_tree_reg.htm#:~:text=Decision%20tree%20builds%20regression%20or,decision%20nodes%20and%20leaf%20nodes.
